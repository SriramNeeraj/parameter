In theoretical physics, fine-tuning is the process in which parameters of a model must be adjusted very precisely in order to fit with certain observations.1, fine-tuning consists of the following four steps: Pretrain a neural network model, i.e., the source model, on a source dataset (e.g., the ImageNet dataset). Create a new neural network model, i.e., the target model. This copies all model designs and their parameters on the source model except the output layer.Finetuning means taking weights of a trained neural network and use it as initialization for a new model being trained on data from the same domain (often e.g. images). It is used to: speed up the training.Feature extraction – We can use a pre-trained model as a feature extraction mechanism. ... 
Use the Architecture of the pre-trained model – What we can do is that we use architecture of the model while we initialize all the weights randomly and train the model according to our dataset again.Fine-tuning in NLP refers to the procedure of re-training a pre-trained language model using your own custom data. As a result of the fine-tuning procedure, the weights of the original model are updated to account for the characteristics of the domain data and the task you are interested in.import tensorflow as tf. from tensorflow import keras.
import keras_tuner as kt.
(img_train, label_train), (img_test, label_test) = keras. datasets. ... 
# Normalize pixel values between 0 and 1. ... 
tuner = kt. ... 
stop_early = tf. ... 
tuner. ... 
# Build the model with the optimal hyperparameters and train it on the data for 50 epochs.Tuning our hyperparameter using Keras Tuner
Step:- 1 ( Download and Prepare the dataset )
Step:- 2 ( Developing the baseline model )
Step:- 3 ( Compiling and Training the model )
Step:- 4 ( Evaluating our model )
Step:- 1 (Importing the libraries)
Step:- 2 (Building the model using Keras Tuner)The hyper-parameter tuning process is a tightrope walk to achieve a balance between underfitting and overfitting. Underfitting is when the machine learning model is unable to reduce the error for either the test or training set.
